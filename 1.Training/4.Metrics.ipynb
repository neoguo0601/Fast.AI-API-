{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training metrics\n",
    "\n",
    "用于训练fastai模型的度量标准只是获取输入和目标张量的函数，并返回一些感兴趣的度量标准用于训练。 您可以通过定义该类型的函数并将其传递给metrics参数中的Learner来编写自己的度量标准，或者使用以下预定义函数之一。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.basics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预定义指标\n",
    "\n",
    "<b>accuracy</b>\n",
    "\n",
    "`accuracy(input:Tensor, targs:Tensor) → Rank0Tensor`\n",
    "\n",
    "输入为`bs` * `n_classes`时，使用targs计算精度。\n",
    "\n",
    "警告：此度量标准用于对属于单个类的对象进行分类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = tensor([0.4, 0.6], [0.3, 0.7], [0.2, 0.8], [0.6, 0.4], [0.9, 0.1]) # bs = 5, n = 2\n",
    "ys = tensor([1], [0], [1], [0], [1])\n",
    "accuracy(preds, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>accuracy_thresh</b>\n",
    "\n",
    "`accuracy_thresh(y_pred:Tensor, y_true:Tensor, thresh:float=0.5, sigmoid:bool=True) → Rank0Tensor`\n",
    "\n",
    "当y_pred和y_true的大小相同时，计算准确性。\n",
    "\n",
    "在可能应用sigmoid之后将预测与thresh进行比较。 然后我们计算与目标匹配的数字。\n",
    "\n",
    "`注意：此函数适用于单热编码目标（通常在多分类问题中）。`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = tensor([0.4, 0.6], [0.3, 0.7], [0.2, 0.8], [0.6, 0.4], [0.9, 0.1])\n",
    "ys = tensor([0, 1], [1, 0], [0, 1], [1, 0], [0, 1]) \n",
    "accuracy_thresh(preds, ys, thresh=0.65, sigmoid=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>top_k_accuracy</b>\n",
    "\n",
    "`top_k_accuracy(input:Tensor, targs:Tensor, k:int=5) → Rank0Tensor`\n",
    "\n",
    "计算Top-k精度（目标在前k个预测中）。\n",
    "\n",
    "<b>dice</b>\n",
    "\n",
    "`dice(input:Tensor, targs:Tensor, iou:bool=False, eps:float=1e-08) → Rank0Tensor`\n",
    "\n",
    "二进制目标的骰子系数度量。 如果iou = True，则返回iou metric，classic是分段问题。\n",
    "\n",
    "$$dice = \\frac{2(TP)}{2(TP) + FP + FN}$$\n",
    "其中TP，FP和FN是真阳性，假阳性和假阴性的数量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6667)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = tensor([0.4, 0.6], [0.3, 0.7], [0.2, 0.8], [0.6, 0.4], [0.9, 0.1])\n",
    "ys = tensor([1], [0], [1], [0], [1])\n",
    "dice(preds, ys) # TP = 2, FP = 1, FN = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>error_rate</b>\n",
    "\n",
    "`error_rate(input:Tensor, targs:Tensor) → Rank0Tensor`\n",
    "\n",
    "1 - accuracy\n",
    "\n",
    "<b>mean_squared_error</b>\n",
    "\n",
    "`mean_squared_error(pred:Tensor, targ:Tensor) → Rank0Tensor`\n",
    "\n",
    "pred和targ之间的均方误差。\n",
    "\n",
    "<b>mean_absolute_error</b>\n",
    "\n",
    "`mean_absolute_error(pred:Tensor, targ:Tensor) → Rank0Tensor`\n",
    "\n",
    "pred和targ之间的平均绝对误差。\n",
    "\n",
    "<b>mean_squared_logarithmic_error</b>\n",
    "\n",
    "`mean_squared_logarithmic_error(pred:Tensor, targ:Tensor) → Rank0Tensor`\n",
    "\n",
    "pred和targ之间的平均对数误差。\n",
    "\n",
    "<b>exp_rmspe</b>\n",
    "\n",
    "`exp_rmspe(pred:Tensor, targ:Tensor) → Rank0Tensor`\n",
    "\n",
    "Exp和pred之间的RMSE。\n",
    "\n",
    "<b>root_mean_squared_error</b>\n",
    "\n",
    "`root_mean_squared_error(pred:Tensor, targ:Tensor) → Rank0Tensor`\n",
    "\n",
    "pred和targ之间的均方根误差。\n",
    "\n",
    "<b>fbeta</b>\n",
    "\n",
    "`fbeta(y_pred:Tensor, y_true:Tensor, thresh:float=0.2, beta:float=2, eps:float=1e-09, sigmoid:bool=True) → Rank0Tensor`\n",
    "\n",
    "计算preds和目标之间的f_beta\n",
    "\n",
    "beta确定应用的fbeta的值，eps用于数值稳定性。 如果sigmoid = True，则在将它们与阈值进行比较然后与目标进行比较之前，将sigmoid应用于预测。 有关fbeta分数的详细信息，请参阅F1得分维基百科页面。\n",
    "\n",
    "$${F_\\beta} = (1+\\beta^2)\\frac{precision \\cdot recall}{(\\beta^2 \\cdot precision) + recall}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6667)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = tensor([0.6, 0.8, 0.2, 0.4, 0.9]).view(1, 5) # TP =2, FP = 1, FN = 1\n",
    "ys = tensor([1, 0, 0, 1, 1]).view(1, 5)\n",
    "fbeta(preds, ys, thresh=0.5, sigmoid=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`注意：此函数适用于单热编码目标（通常在多分类问题中）。`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>explained_variance</b>\n",
    "\n",
    "`explained_variance(pred:Tensor, targ:Tensor) → Rank0Tensor`\n",
    "\n",
    "解释pred和targ之间的差异。\n",
    "\n",
    "$$ Explained \\ Variance = 1 - \\frac{Var( targ - pred )}{Var( targ )}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9374)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = tensor([0.10, .20, .30, .40, .50])\n",
    "ys = tensor([0.12, .17, .25, .44, .56]) # predictions are close to the truth\n",
    "explained_variance(preds, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>r2_score</b>\n",
    "\n",
    "`r2_score(pred:Tensor, targ:Tensor) → Rank0Tensor`\n",
    "\n",
    "pred和targ之间的R2得分（确定系数）。\n",
    "\n",
    "$$ {R^2} = 1 - \\frac{\\sum( targ - pred )^2}{\\sum( targ - \\overline{targ})^2}$$\n",
    "其中 $\\overline{targ}$ 是targ张量的平均值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9351)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(preds, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下度量标准是类，在将它们传递给学习者时不要忘记实例化它们。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>class RMSE</b>\n",
    "\n",
    "`RMSE() :: RegMetrics`\n",
    "\n",
    "计算均方根误差。\n",
    "\n",
    "<b>class ExpRMSPE</b>\n",
    "\n",
    "`ExpRMSPE() :: RegMetrics`\n",
    "\n",
    "计算均方根误差的指数。\n",
    "\n",
    "<b>class Precision</b>\n",
    "\n",
    "`Precision(average:Optional[str]='binary', pos_label:int=1, eps:float=1e-09) :: CMScores`\n",
    "\n",
    "计算精度。\n",
    "\n",
    "<b>class Recall</b>\n",
    "\n",
    "`Recall(average:Optional[str]='binary', pos_label:int=1, eps:float=1e-09) :: CMScores`\n",
    "\n",
    "计算召回。\n",
    "\n",
    "<b>class FBeta</b>\n",
    "\n",
    "`FBeta(average:Optional[str]='binary', pos_label:int=1, eps:float=1e-09, beta:float=2) :: CMScores`\n",
    "\n",
    "计算Fbeta分数。\n",
    "\n",
    "<b>class R2Score</b>\n",
    "\n",
    "`R2Score() :: RegMetrics`\n",
    "\n",
    "计算R2分数（确定系数）。\n",
    "\n",
    "<b>class ExplainedVariance</b>\n",
    "\n",
    "`ExplainedVariance() :: RegMetrics`\n",
    "\n",
    "计算解释的方差。\n",
    "\n",
    "<b>class MatthewsCorreff</b>\n",
    "\n",
    "`MatthewsCorreff() :: ConfusionMatrix`\n",
    "\n",
    "Computes the Matthews correlation coefficient.\n",
    "\n",
    "Ref.: https://github.com/scikit-learn/scikit-learn/blob/bac89c2/sklearn/metrics/classification.py\n",
    "\n",
    "<b>class KappaScore</b>\n",
    "\n",
    "`KappaScore(weights:Optional[str]=None) :: ConfusionMatrix`\n",
    "        \n",
    "计算协议的比率（Cohens Kappa）。\n",
    "\n",
    "Ref.: https://github.com/scikit-learn/scikit-learn/blob/bac89c2/sklearn/metrics/classification.py\n",
    "        \n",
    "`KappaScore`支持ConfusionMatrix中非对角线单元格的线性和二次权重，此外还有默认的未加权计算，将所有误分类视为等权重。 将KappaScore的权重属性保留为None将返回未加权的Kappa分数。 将权重更新为“线性”意味着非对角线的ConfusionMatrix元素与它们距对角线的距离成线性比例加权; “二次”表示权重与它们与对角线的距离成比例的平方。 指定线性或二次权重（如果使用），首先创建度量的实例，然后更新权重属性，类似如下：\n",
    "\n",
    "```python\n",
    "kappa = KappaScore()\n",
    "kappa.weights = \"quadratic\"\n",
    "learn = cnn_learner(data, model, metrics=[error_rate, kappa])\n",
    "```\n",
    "\n",
    "<b>class ConfusionMatrix</b>\n",
    "\n",
    "`ConfusionMatrix() :: Callback`\n",
    "\n",
    "计算混淆矩阵。\n",
    "\n",
    "<b>class MultiLabelFbeta</b>\n",
    "\n",
    "`MultiLabelFbeta(learn, beta=2, eps=1e-15, thresh=0.3, sigmoid=True, average='micro') :: LearnerCallback`\n",
    "\n",
    "计算多标签分类的fbeta分数\n",
    "\n",
    "MultiLabelFbeta实现了mutlilabel分类fbeta得分，类似于scikit-learn's作为LearnerCallback。 平均期权：[\"micro\", \"macro\", \"weighted\", \"none\"]。 旨在与1和0的单热编码目标一起使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating your own metric\n",
    "创建新指标可以像创建新功能一样简单。如果您的度量标准是数据集中元素总数的平均值，那么只需编写将在批处理中计算它的函数（将pred和targ作为参数）。然后将自动对批次进行平均（考虑不同的尺寸）。\n",
    "\n",
    "有时，指标不是简单的平均值。例如，如果我们以精度为例，我们必须将真阳性的数量除以我们为该类所做的预测数量。这不是我们在数据集中的元素数量的平均值，我们只考虑那些我们对特定事物做出正面预测的那些。计算每个批次的精确度，然后对它们求平均值将产生可能接近实际值的结果，但不会完全正确（并且它实际上取决于您如何处理0正面预测的特殊情况）。\n",
    "\n",
    "这就是为什么在fastai中，每个指标都被实现为回调。如果传递常规函数，库会将其转换为名为AverageCallback的正确回调。回调指标仅在验证阶段调用，且仅适用于以下事件：\n",
    "* `on_epoch_begin`（用于初始化）\n",
    "* `on_batch_begin`（如果我们需要查看输入/目标并可能修改它们）\n",
    "* `on_batch_end`（分析最后的结果并更新我们的计算）\n",
    "* `on_epoch_end`（包含应添加到last_metrics的最终结果）\n",
    "\n",
    "例如，以下代码是AverageMetric回调的精确实现，它将函数（如准确性）转换为度量回调。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMetric(Callback):\n",
    "    \"Wrap a `func` in a callback for metrics computation.\"\n",
    "    def __init__(self, func):\n",
    "        # If it's a partial, use func.func\n",
    "        name = getattr(func,'func',func).__name__\n",
    "        self.func, self.name = func, name\n",
    "\n",
    "    def on_epoch_begin(self, **kwargs):\n",
    "        \"Set the inner value to 0.\"\n",
    "        self.val, self.count = 0.,0\n",
    "\n",
    "    def on_batch_end(self, last_output, last_target, **kwargs):\n",
    "        \"Update metric computation with `last_output` and `last_target`.\"\n",
    "        if not is_listy(last_target): last_target=[last_target]\n",
    "        self.count += last_target[0].size(0)\n",
    "        val = self.func(last_output, *last_target)\n",
    "        self.val += last_target[0].size(0) * val.detach().cpu()\n",
    "\n",
    "    def on_epoch_end(self, last_metrics, **kwargs):\n",
    "        \"Set the final result in `last_metrics`.\"\n",
    "        return add_metrics(last_metrics, self.val/self.count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里add_metrics是一个便利函数，它将为我们返回正确的字典：\n",
    "\n",
    "`{'last_metrics': last_metrics + [self.val/self.count]}`\n",
    "\n",
    "这是另一个适当计算给定类的精度的示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Precision(Callback):\n",
    "    \n",
    "    def on_epoch_begin(self, **kwargs):\n",
    "        self.correct, self.total = 0, 0\n",
    "    \n",
    "    def on_batch_end(self, last_output, last_target, **kwargs):\n",
    "        preds = last_output.argmax(1)\n",
    "        self.correct += ((preds==0) * (last_target==0)).float().sum()\n",
    "        self.total += (preds==0).float().sum()\n",
    "    \n",
    "    def on_epoch_end(self, last_metrics, **kwargs):\n",
    "        return add_metrics(last_metrics, self.correct/self.total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下自定义回调类示例测量每个时期内的峰值RAM使用情况："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tracemalloc\n",
    "class TraceMallocMetric(Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.name = \"peak RAM\"\n",
    "\n",
    "    def on_epoch_begin(self, **kwargs):\n",
    "        tracemalloc.start()\n",
    "        \n",
    "    def on_epoch_end(self, last_metrics, **kwargs):\n",
    "        current, peak =  tracemalloc.get_traced_memory()\n",
    "        tracemalloc.stop()\n",
    "        return add_metrics(last_metrics, torch.tensor(peak))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要部署它，您需要在metrics参数中传递此自定义指标的实例：\n",
    "\n",
    "```python\n",
    "learn = cnn_learner(data, model, metrics=[accuracy, TraceMallocMetric()])\n",
    "learn.fit_one_cycle(3, max_lr=1e-2)\n",
    "```\n",
    "\n",
    "然后输出变为：\n",
    "\n",
    "```output\n",
    "Total time: 00:54\n",
    "epoch   train_loss  valid_loss  accuracy    peak RAM\n",
    "   1    0.333352    0.084342    0.973800    2395541.000000\n",
    "   2    0.096196    0.038386    0.988300    2342145.000000\n",
    "   3    0.048722    0.029234    0.990200    2342680.000000\n",
    "```\n",
    "如前所述，将metrics参数与自定义指标类一起使用时，它可以访问的回调系统的阶段数量有限，它只能返回一个数值，因为您可以看到其输出被硬编码为具有6个精度点 在输出中，即使数字是int。\n",
    "\n",
    "为了克服这些限制，应该使用回调类。\n",
    "\n",
    "例如，以下类：\n",
    "\n",
    "* 使用不适用于度量标准类的阶段\n",
    "* 它报告3列，而不是只有一列\n",
    "* 它的列报告是int而不是浮点数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tracemalloc\n",
    "class TraceMallocMultiColMetric(LearnerCallback):\n",
    "    _order=-20 # Needs to run before the recorder\n",
    "    def __init__(self, learn):\n",
    "        super().__init__(learn)\n",
    "        self.train_max = 0\n",
    "\n",
    "    def on_train_begin(self, **kwargs):\n",
    "        self.learn.recorder.add_metric_names(['used', 'max_used', 'peak'])\n",
    "            \n",
    "    def on_batch_end(self, train, **kwargs):\n",
    "        # track max memory usage during the train phase\n",
    "        if train:\n",
    "            current, peak =  tracemalloc.get_traced_memory()\n",
    "            self.train_max = max(self.train_max, current)\n",
    "        \n",
    "    def on_epoch_begin(self, **kwargs):\n",
    "        tracemalloc.start()\n",
    "\n",
    "    def on_epoch_end(self, last_metrics, **kwargs):\n",
    "        current, peak =  tracemalloc.get_traced_memory()\n",
    "        tracemalloc.stop()\n",
    "        return add_metrics(last_metrics, [current, self.train_max, peak])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意，它是LearnerCallback的子类，而不是Callback，因为前者提供了后者不具备的额外功能。\n",
    "\n",
    "另外_order = -20是至关重要的 - 如果没有它，将不会添加自定义列 - 它告诉回调系统在记录器系统之前运行此回调。\n",
    "\n",
    "要部署它，您需要在callback_fns参数中传递该类的名称（而不是实例！）。 这是因为学习对象尚不存在，并且需要实例化TraceMallocMultiColMetric。 一旦创建了学习对象，系统就会自动为我们完成。\n",
    "\n",
    "```python\n",
    "learn = cnn_learner(data, model, metrics=[accuracy], callback_fns=TraceMallocMultiColMetric)\n",
    "learn.fit_one_cycle(3, max_lr=1e-2)\n",
    "```\n",
    "然后输出变为：\n",
    "\n",
    "```python\n",
    "Total time: 00:53\n",
    "epoch   train_loss valid_loss   accuracy     used   max_used   peak\n",
    "    1   0.321233    0.068252    0.978600    156504  2408404   2419891 \n",
    "    2   0.093551    0.032776    0.988500     79343  2408404   2348085\n",
    "    3   0.047178    0.025307    0.992100     79568  2408404   2342754\n",
    "```\n",
    "\n",
    "另一种方法是使用learn.callbacks.append，这次我们需要使用我们现在拥有的学习对象来实例化TraceMallocMultiColMetric，因为它是在创建后者后调用的：\n",
    "\n",
    "```python\n",
    "learn = cnn_learner(data, model, metrics=[accuracy])\n",
    "learn.callbacks.append(TraceMallocMultiColMetric(learn))\n",
    "learn.fit_one_cycle(3, max_lr=1e-2)\n",
    "```\n",
    "在学习对象中配置自定义指标会将它们设置为在将来的所有fit-family调用中运行。 但是，如果您只想为一次调用配置它，可以直接在fit或fit_one_cycle中配置它：\n",
    "\n",
    "```python\n",
    "learn = cnn_learner(data, model, metrics=[accuracy])\n",
    "learn.fit_one_cycle(3, max_lr=1e-2, callbacks=TraceMallocMultiColMetric(learn))\n",
    "```\n",
    "\n",
    "并强调差异：\n",
    "\n",
    "* callback_fns参数需要一个类名或列表\n",
    "* callbacks参数需要一个类的实例或它们的列表\n",
    "* learn.callbacks.append期望一个类的单个实例\n",
    "有关更多示例，请查看fastai代码库及其测试套件，查找继承Callback，LearnerCallback和这两者的子类的类。\n",
    "\n",
    "最后，虽然上面的示例都添加了指标，但这不是必需的。 回调可以执行任何需要的操作，并且不需要将其结果添加到度量标准打印输出中。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
