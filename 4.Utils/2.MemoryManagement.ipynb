{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utils.mem\n",
    "## Memory management utils\n",
    "内存管理的实用功能。 目前主要用于GPU。\n",
    "\n",
    "<b>gpu_mem_get</b>\n",
    "\n",
    "`gpu_mem_get(id=None)`\n",
    "\n",
    "获取所有gpu id，已用和可用内存（以MB为单位）。 如果未传递id，则使用当前选择的torch设备\n",
    "\n",
    "`gpu_mem_get`\n",
    "* for gpu returns GPUMemory(total, free, used)\n",
    "* for cpu returns GPUMemory(0, 0, 0)\n",
    "* for invalid gpu id returns GPUMemory(0, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.utils.mem import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPUMemory(total=4096, free=3934, used=161)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_mem_get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>gpu_mem_get_all</b>\n",
    "\n",
    "`gpu_mem_get_all()`\n",
    "\n",
    "获取每个可用gpu的总内存，已用内存和可用内存（以MB为单位）\n",
    "\n",
    "`gpu_mem_get_all`\n",
    "\n",
    "for gpu returns [ GPUMemory(total_0, free_0, used_0), GPUMemory(total_1, free_1, used_1), .... ]\n",
    "for cpu returns []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[GPUMemory(total=4096, free=3934, used=161)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_mem_get_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>gpu_mem_get_free</b>\n",
    "\n",
    "`gpu_mem_get_free()`\n",
    "\n",
    "获取当前所选gpu id的空闲内存（以MB为单位），无需清空缓存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3934"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_mem_get_free()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>gpu_mem_get_free_no_cache</b>\n",
    "\n",
    "`gpu_mem_get_free_no_cache()`\n",
    "\n",
    "在清空缓存后，获取当前所选gpu id的空闲内存（以MB为单位）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3934"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_mem_get_free_no_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>gpu_mem_get_used</b>\n",
    "\n",
    "`gpu_mem_get_used()`\n",
    "\n",
    "获取当前所选gpu id的内存（以MB为单位），不用清空缓存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_mem_get_used()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>gpu_mem_get_used_no_cache</b>\n",
    "\n",
    "`gpu_mem_get_used_no_cache()`\n",
    "\n",
    "在清空缓存后，获取当前所选gpu id的内存（以MB为单位）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_mem_get_used_no_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>gpu_mem_get_used_fast</b>\n",
    "\n",
    "`gpu_mem_get_used_fast(gpu_handle)`\n",
    "\n",
    "获取当前所选gpu id的内存（以MB为单位），不清空缓存，需要gpu_handle arg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>gpu_with_max_free_mem</b>\n",
    "\n",
    "`gpu_with_max_free_mem()`\n",
    "\n",
    "为具有最高可用RAM的第一个gpu获取[gpu_id，its_free_ram]\n",
    "\n",
    "gpu_with_max_free_mem:\n",
    "\n",
    "* for gpu returns: gpu_with_max_free_ram_id, its_free_ram\n",
    "* for cpu returns: None, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 3934)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_with_max_free_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>preload_pytorch</b>\n",
    "\n",
    "`preload_pytorch()`\n",
    "\n",
    "preload_pytorch在测量GPU内存时很有用，因为第一次对cuda进行任何操作都是由pytorch执行的，通常大约0.5GB被CUDA上下文使用。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "preload_pytorch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>class GPUMemory</b>\n",
    "\n",
    "`GPUMemory(total, free, used) :: tuple`\n",
    "\n",
    "GPUMemory是一个由gpu_mem_get和gpu_mem_get_all等函数返回的namedtuple。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>b2mb</b>\n",
    "\n",
    "`b2mb(num)`\n",
    "\n",
    "将Bs转换为MB并向下舍入\n",
    "\n",
    "b2mb是一个帮助实用程序，只执行int（bytes / 2 ** 20）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Tracing Utils\n",
    "<b>class GPUMemTrace</b>\n",
    "\n",
    "`GPUMemTrace(silent=False, ctx=None, on_exit_report=True)`\n",
    "\n",
    "跟踪分配和峰值GPU内存使用（增量）。\n",
    "\n",
    "参数：\n",
    "\n",
    "* silent：生成报告和report_n_reset的快捷方式，无需删除这些调用 - 这可以从构造函数中完成，或者您可以在任何地方调用静默方法来执行相同操作。\n",
    "* ctx：报告中的默认上下文注释\n",
    "* on_exit_report：ctx manager exit上的自动报告（默认为True）\n",
    "\n",
    "定义：\n",
    "\n",
    "* Delta Used是当前使用的内存与计数器开始时使用的内存之间的差异。\n",
    "\n",
    "* Delta Peaked是内存开销，如果有的话。 它分两步计算：\n",
    "\n",
    "    1. 基本测量值是计数器开始时峰值存储器和已用存储器之间的差值。\n",
    "    2. 然后，如果使用的delta为正，则从基值中减去。\n",
    "\n",
    "        它表示blip的大小。\n",
    "\n",
    "        警告：目前高峰内存使用情况跟踪是使用python线程实现的，这是非常不可靠的，因为无法保证线程在峰值内存发生时有机会运行（或者它可能没有机会 一直跑。） 因此我们需要pytorch来实现多个并发和可重置的torch.cuda.max_memory_allocated计数器。 请投票支持此功能请求。\n",
    "        \n",
    "用法示例：\n",
    "\n",
    "Setup："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.utils.mem import GPUMemTrace\n",
    "def some_code(): pass\n",
    "mtrace = GPUMemTrace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例1：通过报告（打印）和通过数据（返回）访问器进行的基本测量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "△Used Peaked MB:      0      0\n",
      "△Used Peaked MB:      0      0 (2nd run of some_code())\n"
     ]
    }
   ],
   "source": [
    "some_code()\n",
    "mtrace.report()\n",
    "delta_used, delta_peaked = mtrace.data()\n",
    "\n",
    "some_code()\n",
    "mtrace.report('2nd run of some_code()')\n",
    "delta_used, delta_peaked = mtrace.data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果您有许多报表调用，并且想要了解哪个是输出中的哪个，那么report的可选subctx参数会很有用。\n",
    "\n",
    "示例2：循环测量，在每次运行之前重置计数器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "△Used Peaked MB:      0      0 (i=0)\n",
      "△Used Peaked MB:      0      0 (i=1)\n",
      "△Used Peaked MB:      0      0 (i=2)\n",
      "△Used Peaked MB:      0      0 (i=3)\n",
      "△Used Peaked MB:      0      0 (i=4)\n",
      "△Used Peaked MB:      0      0 (i=5)\n",
      "△Used Peaked MB:      0      0 (i=6)\n",
      "△Used Peaked MB:      0      0 (i=7)\n",
      "△Used Peaked MB:      0      0 (i=8)\n",
      "△Used Peaked MB:      0      0 (i=9)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    mtrace.reset()\n",
    "    some_code()\n",
    "    mtrace.report(f'i={i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reset重置所有计数器。\n",
    "\n",
    "示例3：与示例2类似，但报告会自动重置计数器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "△Used Peaked MB:      0      0 (i=0)\n",
      "△Used Peaked MB:      0      0 (i=1)\n",
      "△Used Peaked MB:      0      0 (i=2)\n",
      "△Used Peaked MB:      0      0 (i=3)\n",
      "△Used Peaked MB:      0      0 (i=4)\n",
      "△Used Peaked MB:      0      0 (i=5)\n",
      "△Used Peaked MB:      0      0 (i=6)\n",
      "△Used Peaked MB:      0      0 (i=7)\n",
      "△Used Peaked MB:      0      0 (i=8)\n",
      "△Used Peaked MB:      0      0 (i=9)\n"
     ]
    }
   ],
   "source": [
    "mtrace.reset()\n",
    "for i in range(10):\n",
    "    some_code()\n",
    "    mtrace.report_n_reset(f'i={i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建GPUMemTrace对象后立即开始跟踪，并在删除该对象时停止。 但它也可以停止，也可以手动启动。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrace.start()\n",
    "mtrace.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果要冻结GPUMemTrace对象并且能够在某个时间停止查询其数据，则stop特别有用。\n",
    "\n",
    "<b>报告：</b>\n",
    "\n",
    "在报表中，您可以打印通过构造函数传递的主要上下文："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "△Used Peaked MB:      0      0 (foobar)\n"
     ]
    }
   ],
   "source": [
    "mtrace = GPUMemTrace(ctx=\"foobar\")\n",
    "mtrace.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后根据需要添加子上下文注释："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "△Used Peaked MB:      0      0 (foobar: 1st try)\n",
      "△Used Peaked MB:      0      0 (foobar: 2nd try)\n"
     ]
    }
   ],
   "source": [
    "mtrace = GPUMemTrace(ctx=\"foobar\")\n",
    "mtrace.report('1st try')\n",
    "mtrace.report('2nd try')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上下文和子上下文都是可选的，如果您在代码周围的不同位置放置GPUMemTrace，它们非常有用。\n",
    "\n",
    "您可以静默报告调用，无需通过构造函数或静默删除它们："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "△Used Peaked MB:      0      0\n"
     ]
    }
   ],
   "source": [
    "mtrace = GPUMemTrace(silent=True)\n",
    "mtrace.report() # nothing will be printed\n",
    "mtrace.silent = False\n",
    "mtrace.report() # printing resumed\n",
    "mtrace.silent = True\n",
    "mtrace.report() # nothing will be printed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Context Manager:</b>\n",
    "\n",
    "GPUMemTrace也可以用作上下文管理器：\n",
    "\n",
    "自动报告已使用和已达到峰值的增量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "△Used Peaked MB:      0      0 (exit)\n"
     ]
    }
   ],
   "source": [
    "with GPUMemTrace(): some_code()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果您想添加上下文："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "△Used Peaked MB:      0      0 (some context: exit)\n"
     ]
    }
   ],
   "source": [
    "with GPUMemTrace(ctx='some context'): some_code()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上下文管理器使用子上下文退出来指示在退出上下文之后报告。\n",
    "\n",
    "报告是自动完成的，由于返回调用，这在函数中特别有用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "△Used Peaked MB:      0      0 (some_func: exit)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def some_func():\n",
    "    with GPUMemTrace(ctx='some_func'):\n",
    "        # some code\n",
    "        return 1\n",
    "some_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以尽管调用，你仍然可以获得完美的报告。 ctx对于指定上下文非常有用，以防您通过代码进行了许多调用，并且想知道哪个是哪个。\n",
    "\n",
    "当然，除了执行上述操作之外，您还可以使用gpu_mem_trace装饰器自动执行此操作，包括使用函数或方法名称作为上下文。 因此，下面的示例在不修改函数的情况下也是如此。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "△Used Peaked MB:      0      0 (some_func: exit)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@gpu_mem_trace\n",
    "def some_func():\n",
    "    # some code\n",
    "    return 1\n",
    "some_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果您不希望自动报告，只需在构造函数中传递on_exit_report = False："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "△Used Peaked MB:      0      0 (some_func: measured in ctx)\n"
     ]
    }
   ],
   "source": [
    "with GPUMemTrace(ctx='some_func', on_exit_report=False) as mtrace:\n",
    "    some_code()\n",
    "mtrace.report(\"measured in ctx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "或与上下文注释相同："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "△Used Peaked MB:      0      0\n"
     ]
    }
   ],
   "source": [
    "with GPUMemTrace(on_exit_report=False) as mtrace: some_code()\n",
    "print(mtrace) # or mtrace.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当然，您可以获得数值数据（以舍入的MB为单位）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "△Used Peaked MB:      0      0 (exit)\n"
     ]
    }
   ],
   "source": [
    "with GPUMemTrace() as mtrace: some_code()\n",
    "delta_used, delta_peaked = mtrace.data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>gpu_mem_trace</b>\n",
    "\n",
    "`gpu_mem_trace(func)`\n",
    "\n",
    "一个装饰器，运行GPUMemTrace w/ 报告方法\n",
    "\n",
    "这允许您使用以下内容修饰任何函数或方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "△Used Peaked MB:      0      0 (my_function: exit)\n"
     ]
    }
   ],
   "source": [
    "@gpu_mem_trace\n",
    "def my_function(): pass\n",
    "# run:\n",
    "my_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "它将自动打印包含函数名称的报告作为上下文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
